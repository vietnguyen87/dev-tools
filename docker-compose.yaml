version: '3'

services:
  es01:
    build: docker-box/elasticsearch
    image: elasticsearch
    container_name: es01
    environment:
      - node.name=es01
      - cluster.name=esv7product
      - discovery.seed_hosts=es02,es03
      - cluster.initial_master_nodes=es01,es02,es03
      - "cluster.routing.allocation.disk.watermark.low=5gb" #Elasticsearch will not allocate shards to nodes that have more than 5gb disk used.
      - "cluster.routing.allocation.disk.watermark.high=2gb" #Elasticsearch will attempt to relocate shards away from a node whose disk usage is above 2gb.
      - "cluster.routing.allocation.disk.watermark.flood_stage=1gb" #This setting is a last resort to prevent nodes from running out of disk space.
      - "cluster.info.update.interval=1m" #Elasticsearch should check on disk usage for each node in the cluster. Defaults to 30s.
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - ./data/elasticsearch/data01:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
    profiles: ["elasticsearch"]
    networks:
      - backend

  es02:
    build: docker-box/elasticsearch
    image: elasticsearch
    container_name: es02
    environment:
      - node.name=es02
      - cluster.name=esv7product
      - discovery.seed_hosts=es01,es03
      - cluster.initial_master_nodes=es01,es02,es03
      - "cluster.routing.allocation.disk.watermark.low=5gb" #Elasticsearch will not allocate shards to nodes that have more than 5gb disk used.
      - "cluster.routing.allocation.disk.watermark.high=2gb" #Elasticsearch will attempt to relocate shards away from a node whose disk usage is above 2gb.
      - "cluster.routing.allocation.disk.watermark.flood_stage=1gb" #This setting is a last resort to prevent nodes from running out of disk space.
      - "cluster.info.update.interval=1m" #Elasticsearch should check on disk usage for each node in the cluster. Defaults to 30s.
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - ./data/elasticsearch/data02:/usr/share/elasticsearch/data
    profiles: ["elasticsearch"]
    networks:
      - backend

  es03:
    build: docker-box/elasticsearch
    image: elasticsearch
    container_name: es03
    environment:
      - node.name=es03
      - cluster.name=esv7product
      - discovery.seed_hosts=es01,es02
      - cluster.initial_master_nodes=es01,es02,es03
      - "cluster.routing.allocation.disk.watermark.low=5gb" #Elasticsearch will not allocate shards to nodes that have more than 5gb disk used.
      - "cluster.routing.allocation.disk.watermark.high=2gb" #Elasticsearch will attempt to relocate shards away from a node whose disk usage is above 2gb.
      - "cluster.routing.allocation.disk.watermark.flood_stage=1gb" #This setting is a last resort to prevent nodes from running out of disk space.
      - "cluster.info.update.interval=1m" #Elasticsearch should check on disk usage for each node in the cluster. Defaults to 30s.
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - ./data/elasticsearch/data03:/usr/share/elasticsearch/data
    profiles: ["elasticsearch"]
    networks:
      - backend

  kafdrop:
    image: obsidiandynamics/kafdrop
    restart: "no"
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKERCONNECT: "kafka:29092"
      JVM_OPTS: "-Xms16M -Xmx48M -Xss180K -XX:-TieredCompilation -XX:+UseStringDeduplication -noverify"
    depends_on:
      - "kafka"
    profiles: ["kafka"]
    networks:
      - backend

  kafka:
    image: obsidiandynamics/kafka
    restart: "no"
    ports:
      - "2181:2181"
      - "9092:9092"
    profiles: ["dev", "kafka"]
    environment:
      KAFKA_LISTENERS: "INTERNAL://:29092,EXTERNAL://:9092"
      KAFKA_ADVERTISED_LISTENERS: "INTERNAL://kafka:29092,EXTERNAL://localhost:9092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"
      KAFKA_ZOOKEEPER_SESSION_TIMEOUT: "6000"
      KAFKA_RESTART_ATTEMPTS: "10"
      KAFKA_RESTART_DELAY: "5"
      ZOOKEEPER_AUTOPURGE_PURGE_INTERVAL: "0"
    networks:
      - backend

  mongodb:
    build: docker-box/mongodb
    image: mongodb
    restart: on-failure
    environment:
      - MONGO_INITDB_ROOT_USERNAME=u_test
      - MONGO_INITDB_ROOT_PASSWORD=Him3d3jmuDGD
      - MONGO_INITDB_DATABASE=admin
    volumes:
      - ${DATA_PATH}/mongodb:/data/db
      - ${DATA_PATH}/mongo-entrypoint:/docker-entrypoint-initdb.d/
      - ${DATA_PATH}/mongo_config:/data/configdb
#      - ./data/mongodb:/data/db
#      - ./data/mongodb/logs:/var/log/mongodb/
    profiles: ["dev", "mongodb"]
    ports:
      - 27017:27017
    networks:
      - backend

  redis-node-0:
    image: docker.io/bitnami/redis-cluster:latest
    ports:
      - "6380:6379"
    restart: always
    volumes:
      - ${DATA_PATH}/redis/node0:/bitnami/redis/data
    environment:
      - 'ALLOW_EMPTY_PASSWORD=yes'
      - 'REDIS_PORT=6379'
      - 'REDIS_NODES=redis-node-0 redis-node-1 redis-node-2'
      - 'REDIS_CLUSTER_CREATOR=yes'
    profiles: ["dev", "redis"]
    networks:
      - backend

  redis-node-1:
    image: docker.io/bitnami/redis-cluster:latest
    ports:
      - "6381:6379"
    volumes:
      - ${DATA_PATH}/redis/node1:/bitnami/redis/data
    environment:
      - 'ALLOW_EMPTY_PASSWORD=yes'
      - 'REDIS_PORT=6379'
      - 'REDIS_NODES=redis-node-0 redis-node-1 redis-node-2'
      - 'REDIS_CLUSTER_CREATOR=yes'
    profiles: ["dev", "redis"]
    networks:
      - backend

  redis-node-2:
    image: docker.io/bitnami/redis-cluster:latest
    ports:
      - "6382:6379"
    volumes:
      - ${DATA_PATH}/redis/node2:/bitnami/redis/data
    environment:
      - 'ALLOW_EMPTY_PASSWORD=yes'
      - 'REDIS_PORT=6379'
      - 'REDIS_NODES=redis-node-0 redis-node-1 redis-node-2'
      - 'REDIS_CLUSTER_CREATOR=yes'
    profiles: ["dev", "redis"]
    networks:
      - backend

  redis-cluster-init:
    image: docker.io/bitnami/redis-cluster:latest
    restart: "no"
    depends_on:
      - redis-node-0
      - redis-node-1
      - redis-node-2
    ports:
      - 6383:6379
    environment:
      - 'ALLOW_EMPTY_PASSWORD=yes'
      - 'REDIS_CLUSTER_REPLICAS=1'
      - 'REDIS_NODES=redis-node-0 redis-node-1 redis-node-2'
      - 'REDIS_CLUSTER_CREATOR=yes'
    profiles: ["dev", "redis"]
    networks:
      - backend

  # Grafana
  grafana:
    image: grafana/grafana
    user: root
    volumes:
      - ${DATA_PATH}/grafana:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_USER=${GF_SECURITY_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GF_SECURITY_ADMIN_PASSWORD:-admin}
      - VIRTUAL_HOST=grafana.${BASE_DOMAIN}
      - VIRTUAL_PORT=3000
      - LETSENCRYPT_HOST=grafana.${BASE_DOMAIN}
    restart: always
    networks:
      - backend
    profiles: [ "dev", "grafana" ]

  # Prometheus
  prometheus:
    image: prom/prometheus
    user: root
    ports:
      - "9090:9090"
    volumes:
      - ./container/prometheus/config:/config
      - ${DATA_PATH}/prometheus:/data
    command:
      - '--config.file=/config/prometheus.yml'
      - '--storage.tsdb.path=/data'
    restart: always
    networks:
      - backend
    profiles: [ "dev", "prometheus" ]


networks:
  backend:
    driver: bridge
